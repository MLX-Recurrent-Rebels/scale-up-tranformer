{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "85bc3b1d-ba84-493b-99e2-4d117b81550e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.6116, -0.1665, -0.3176,  ...,  0.4913, -0.3003, -0.9186],\n",
      "         [-0.7834,  2.3685,  0.3515,  ...,  1.1737, -0.5143, -0.2452],\n",
      "         [ 0.8846,  2.4703, -1.6669,  ...,  0.9462, -1.1621, -1.6358]],\n",
      "\n",
      "        [[-0.2443,  1.5199,  0.7731,  ...,  0.6395,  0.4989, -1.1354],\n",
      "         [ 0.3121,  2.4009, -1.2952,  ...,  0.0503,  0.1404, -0.8279],\n",
      "         [-0.0592,  0.3156, -0.2504,  ...,  0.4220,  0.2890, -0.4293]],\n",
      "\n",
      "        [[-0.2106,  2.8360, -1.1626,  ..., -0.4826, -0.0120, -1.1384],\n",
      "         [ 1.2401,  0.2684, -0.1622,  ..., -0.9406,  1.3409, -0.4403],\n",
      "         [ 0.1894,  0.3839,  0.2127,  ..., -0.1196, -0.8270,  0.4632]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "torch.Size([3, 3, 16000])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from mha_GPT import Mha_GPT\n",
    "import sentencepiece as spm\n",
    "import torch\n",
    "from my_GPT import GPT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "117506ab-d08b-4640-993e-b8388f81b183",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_attention_heatmap(attention_weights):\n",
    "    sns.heatmap(attention_weights, cmap=\"viridis\", annot=True, fmt=\".2f\", cbar=False)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7284d9f0-001f-4677-8db9-88d6fc6fae08",
   "metadata": {},
   "outputs": [],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(\"tinystories_tokeniser.model\")\n",
    "\n",
    "vocab = [sp.id_to_piece(i) for i in range(sp.get_piece_size())]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "bce52e03-d47f-48cf-a514-c96a0fb8e9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tell_me_a_story(gpt_model, text, counter):\n",
    "    \n",
    "    counter += 1\n",
    "    token_ids = torch.tensor([sp.encode_as_ids(text)])\n",
    "    output = gpt_model(token_ids)\n",
    "\n",
    "    if isinstance(output, tuple) and len(output) == 2:\n",
    "        logits, attention_weights = output\n",
    "    else:\n",
    "        # Handle the case where your model returns only logits\n",
    "        logits = output\n",
    "        \n",
    "        attention_weights = None  # You might need to adjust this based on your model's behavior\n",
    "    logits = logits[0]\n",
    "    \n",
    "   # probs = F.softmax(logits, dim=-1)\n",
    "    predicted_word_index = torch.argmax(logits , dim = 1)\n",
    "   \n",
    "    predicted_word = sp.decode(predicted_word_index[-1].item())\n",
    "   \n",
    "    if  counter == 100:\n",
    "        return text\n",
    "    else:\n",
    "        return tell_me_a_story(gpt_model, text + \" \" + predicted_word, counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15133fae-ea7c-4e82-b98f-5fd778e17304",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "vocab_size = len(vocab)\n",
    "embedding_size = 512\n",
    "max_seq_length = 1194\n",
    "num_heads = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "48a3511e-6c17-4fac-842e-b33abfe6fb84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (embedding): Embedding(16000, 512)\n",
       "  (positional_encoding): PositionalEncoding()\n",
       "  (self_attention): SelfAttention(\n",
       "    (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (linear_key): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (linear_value): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (add_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (feed_forward): FeedForward(\n",
       "    (linear1): Linear(in_features=512, out_features=10, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (linear2): Linear(in_features=10, out_features=512, bias=True)\n",
       "  )\n",
       "  (add_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (fc): Linear(in_features=512, out_features=16000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_gpt_model = Mha_GPT(vocab_size, embedding_size, max_seq_length, num_heads)\n",
    "trained_gpt_model.load_state_dict(torch.load('mha_GPT.pth'))\n",
    "trained_gpt_model.eval()\n",
    "\n",
    "trained_sha_gpt_model = GPT(vocab_size, embedding_size, max_seq_length)\n",
    "trained_sha_gpt_model.load_state_dict(torch.load('my_GPT.pth'))\n",
    "trained_sha_gpt_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "40359a88-72fe-4bec-8c04-54098e9cabcd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Once upon a time , there was a little girl named Lily . She loved to play with his friends . One day , she was a big , \" Look , \" Look , \" Can we can \\' s mom said , \" I \\' s mom said , \" I want to the park . He was very happy . He was so happy and said , \" I want to the little girl was so happy . He was so happy . He was so happy . He was so happy and said , \" I \\' s mom'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tell_me_a_story(trained_sha_gpt_model, \"Once upon a time\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa71dfec-fdcc-4843-a6bf-b447f75d9e01",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_params = sum(p.numel() for p in trained_gpt_model.parameters())\n",
    "print(f'Total parameters in your GPT model: {total_params}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eab28b17-f197-4205-a00e-d1c695b4833d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
