{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "56767734-39f9-4b1d-a95f-f48e69fecc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import custom_dataset\n",
    "from custom_dataset import CustomDataset\n",
    "import sentencepiece as spm\n",
    "import my_GPT\n",
    "from my_GPT import GPT\n",
    "import pickle\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "import os\n",
    "import dataset_bes\n",
    "import collate_fn\n",
    "from datasets import load_dataset\n",
    "\n",
    "# Load the SentencePiece model\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load(\"tinystories_tokeniser.model\")\n",
    "\n",
    "vocab = [sp.id_to_piece(i) for i in range(sp.get_piece_size())]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee70e61c-e717-4805-9fcb-e00dd8dec9cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Repo card metadata block was not found. Setting CardData to empty.\n",
      "Repo card metadata block was not found. Setting CardData to empty.\n"
     ]
    }
   ],
   "source": [
    "data = load_dataset(\"roneneldan/TinyStories\")\n",
    "\n",
    "train_data = data[\"train\"]\n",
    "val_data = data[\"validation\"]\n",
    "ds = dataset_bes.TinyDataset()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af81967a-7326-4e3b-a0ae-bd08e3889e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "dl = torch.utils.data.DataLoader(ds, batch_size=batch_size, shuffle=True, collate_fn=ds.collate_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04f0c9ec-810f-43e9-b239-9c1e17c92c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "vocab_size = len(vocab)\n",
    "embedding_size = 512\n",
    "max_seq_length = 1194\n",
    "#batch_size = 64  # You can adjust this based on your specific requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04df0c6e-72f3-4488-afe6-33bdd6271fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e43b836-d21c-4180-8ecb-1e884c836f44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bbb47ed1-2862-4dc8-bc59-a0a26fd062a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_model = GPT(vocab_size, embedding_size, max_seq_length)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(gpt_model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce93034b-42e9-48e0-9240-3d4fe711979c",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = 'checkpoints/'\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688cde32-7873-4256-af57-3e78d132e8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login(key='0a9583c37867b372d3f0849f8385a8eb0d4c4ec2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c22fe9bd-ee97-4892-adbb-ee07dc486c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wandb.init(project ='Birsen_GPT', entity = 'birsenyildiz2018',     \n",
    "    config={\n",
    "    \"learning_rate\": 0.01,\n",
    "    \"architecture\": \"Single headed GPT\",\n",
    "    \"dataset\": \"Tiny Stories\",\n",
    "    \"epochs\": 10, \n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c6b55c-3e68-44e7-85dc-758584bab4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_texting(text, counter):\n",
    "    counter += 1\n",
    "    token_ids = torch.tensor([sp.encode_as_ids(text)])\n",
    "    logits = gpt_model(token_ids)\n",
    "    probs = F.softmax(logits, dim=-1)\n",
    "    probs = probs[0]\n",
    "    max_value, predicted_word_index = torch.max(probs[:, -1], dim=0)\n",
    "    predicted_word = vocab[predicted_word_index]\n",
    "    if predicted_word == \"</s>\" or counter == 200:\n",
    "        return text + \" \" + predicted_word\n",
    "    else:\n",
    "        return recursive_texting(text + \" \" + predicted_word, counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e219613-76a3-4e09-a999-ce393c177fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "num_epochs = 10  # Adjust as needed\n",
    "checkpoint_interval = 1\n",
    "for epoch in range(num_epochs):\n",
    "    correct_predictions = 0\n",
    "    total_predictions = 0\n",
    "    for batch in dl:\n",
    "        tokens = batch['input']\n",
    "        true_labels = batch['label']\n",
    "        optimizer.zero_grad()\n",
    "        output = gpt_model(batch['input'])\n",
    "        model_output = output.view(-1, vocab_size)  # Reshape to [batch_size * seq_length, num_classes]\n",
    "        true_labels = true_labels.view(-1)  # Reshape to [batch_size * seq_length]\n",
    "        loss = criterion(model_output, true_labels)\n",
    "        max_indices = torch.argmax(model_output, dim=1)\n",
    "        correct_predictions += ((max_indices - true_labels)==0).sum()\n",
    "        total_predictions += len(true_labels)\n",
    "        # correct_predictions += torch.sum(predictions==label)\n",
    "        # total_predictions += batch_size\n",
    "        acc = correct_predictions/total_predictions\n",
    "        # acc = 0\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        wandb.log({\"acc\": acc, \"loss\": loss, \"perp\": math.exp(loss), })\n",
    "        if (epoch + 1) % checkpoint_interval == 0:\n",
    "            checkpoint_path = os.path.join(checkpoint_dir, f'model_epoch_{epoch+1}.pt')\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'model_state_dict': gpt_model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': loss,\n",
    "                'acc': acc,\n",
    "                'perp':math.exp(loss),\n",
    "                'bacth size': batch_size,\n",
    "                'emd_dim':embedding_size\n",
    "                \n",
    "            }, checkpoint_path)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Acc: {acc}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a62e86d-76f8-441d-add1-c2a69d3e3766",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(gpt_model.state_dict(), 'my_GPT.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3182dd9-5975-467b-96dc-33340d2b2119",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT(\n",
       "  (embedding): Embedding(16000, 512)\n",
       "  (positional_encoding): PositionalEncoding()\n",
       "  (self_attention): SelfAttention(\n",
       "    (linear_query): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (linear_key): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (linear_value): Linear(in_features=512, out_features=512, bias=True)\n",
       "  )\n",
       "  (add_norm1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (feed_forward): FeedForward(\n",
       "    (linear1): Linear(in_features=512, out_features=10, bias=True)\n",
       "    (relu): ReLU()\n",
       "    (linear2): Linear(in_features=10, out_features=512, bias=True)\n",
       "  )\n",
       "  (add_norm): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "  (fc): Linear(in_features=512, out_features=16000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "gpt_model = GPT(vocab_size, embedding_size, max_seq_length)\n",
    "gpt_model.load_state_dict(torch.load('my_GPT.pth'))\n",
    "gpt_model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3aa54c4-87e0-4d6b-a807-e5713f4aa56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_ids = torch.tensor([sp.encode_as_ids(\"The apple\")])\n",
    "logits = gpt_model(token_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cf64ca-be3c-4e4d-aebe-e7bb858bd99e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(logits.shape)\n",
    "probs = F.softmax(logits, dim=-1)\n",
    "print(probs)\n",
    "probs = probs[0]\n",
    "print(probs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ff75e6-5ae0-42b4-9e09-9d388bf2aad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "print(vocab[1])\n",
    "# Get the index of the word with the highest probability (argmax)\n",
    "max_value, predicted_word_index = torch.max(probs[:, -1], dim=0)\n",
    "print(predicted_word_index)\n",
    "# You may want to convert this index back to the actual word using your vocabulary\n",
    "predicted_word = vocab[predicted_word_index]\n",
    "print(predicted_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "953679ba-733c-47db-9a04-7566afe6e34c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tell_me_a_story(text, counter):\n",
    "    counter += 1\n",
    "    token_ids = torch.tensor([sp.encode_as_ids(text)])\n",
    "    logits = gpt_model(token_ids)\n",
    "    probs = F.softmax(logits, dim=-1)\n",
    "    predicted_word_index = torch.argmax(probs, dim=-1)\n",
    "    predicted_word = sp.decode(predicted_word_index[0][-1].item())\n",
    "    if predicted_word == \"</s>\" or counter == 200:\n",
    "        return text\n",
    "    else:\n",
    "        return tell_me_a_story(text + \" \" + predicted_word, counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "99e66742-e9f0-4710-8997-6a59af6b1cc6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The blue sky . They like a little girl named Timmy was very happy and loved to play with a big , but he was a big , \" Let \\' s mom . He was so excited to the park . He was so happy to the park . He was a big , \" I \\' t want to the ground . He was a big , \" I \\' t want to the little girl was so happy . He was so happy . He was so happy and said , \" I \\' s mom said , \" I \\' s mom said , \" I \\' s mom said , \" I \\' s mom said , \" I \\' s mom said , \" Yes , \" You should always be careful and said , \" You can \\' s mom and the little girl was a great time , \" You should always be careful and said , \" You are you , \" You are sorry .                           '"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tell_me_a_story(\" The blue sky\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17914f6f-aea4-403a-a519-589377267346",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sp.encode(\" \"))\n",
    "print(sp.decode(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001b3fa8-4986-4b3b-ab97-632b3252cf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2D tensor\n",
    "# Replace this with your actual tensor\n",
    "tensor_2d = torch.tensor([[1, 2, 3],\n",
    "                          [4, 5, 6],\n",
    "                          [7, 8, 9]])\n",
    "\n",
    "# Shift each row backward by 1 position\n",
    "shifted_tensor = torch.cat((tensor_2d[:, 1:], tensor_2d[:, 0:1]), dim=1)\n",
    "\n",
    "print(\"Original Tensor:\")\n",
    "print(tensor_2d)\n",
    "\n",
    "print(\"\\nShifted Tensor:\")\n",
    "print(shifted_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d78f41c9-3760-41db-9a8a-b60e82e8d6a0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
